{"pages":[{"url":"pages/contact.html.html","text":"Contact Oliver Gutsche Communication The project communicates through: Google Group: cms-big-data-project@googlegroups.com (link to subscribe) Slack: Ask for an invite to our Slack team cmsbigdataproject.slack.com or contact Oliver Gutsche Meetings The projects tries to meet bi-weekly. The meetings are announced on the Google group and in slack and Exchange invites are sent out. The meetings have an indico agenda in this indico category . Meetings notes are published after the meeting","tags":"pages","title":"Contact and Communication"},{"url":"pages/datareduction.html.html","text":"CERN openlab/Intel CMS Data Reduction Facility","tags":"pages","title":"CERN openlab/Intel CMS Data Reduction Facility"},{"url":"pages/fullanalysis.html.html","text":"Full HEP Analysis in Apache Spark","tags":"pages","title":"Full HEP Analysis in Apache Spark"},{"url":"pages/hpc.html.html","text":"Big Data Analysis at HPC centers","tags":"pages","title":"Big Data Analysis at HPC centers"},{"url":"pages/.html","text":"The CMS Big Data Project explores the applicability of open source data analytics toolkits to the HEP data analysis challenge Experimental Particle Physics has been at the forefront of analyzing the world's largest datasets for decades. The HEP community was amongst the first to develop suitable software and computing tools for this task. In recent times, new open source toolkits and systems collectively called \"Big Data\" technologies have emerged to support the analysis of Petabyte and Exabyte datasets. While the principles of data analysis in HEP have not changed (filtering and transforming experiment-specific data formats), these new technologies use different approaches and promise a fresh look at analysis of very large datasets and could potentially reduce the time-to-physics with increased interactivity. The CMS Big Data Project explores these new open source data analytics toolkits and has the following goals Reduce time-to-physics Educate our graduate students and post docs to use industry-based technologies Improves chances on the job market outside academia Increases the attractiveness of our field Use tools developed in larger communities reaching outside of our field The starting point is Apache Spark and we are working on the following thrusts Full Analysis in Apache Spark CERN openlab/Intel CMS Big Data Reduction Facility Big Data analytics at HPC centers All thrusts are based on reproducing a CMS physics analysis with open source data analytics frameworks in various settings, based on Apache Spark.","tags":"pages","title":""},{"url":"pages/pubsntalks.html.html","text":"Publications \"Big Data in HEP: A comprehensive use case study\" Proceedings for 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP 2016) accepted for publication arXiv:1703.04171 Talks \"Big Data Reduction - Introduction\" CMS Spring Offline and Computing Week 2016 April 04, 2016 Slides (password protected) \"Big Data\" in HEP: A comprehensive use case study\" 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP 2016) October 13, 2016 Slides \"Big Data Project : Status and Outlook\" CMS Fall Offline and Computing Week 2016 November 10, 2016 Slides (password protected) \"Intel Big Data Project: CMS Physics Data Reduction use case\" CERN openlab Technical Workshop December 09, 2016 Slides \"Status of CMS Big Data Project\" R&D meeting of CMS Spring Offline and Computing Week 2017 April 04, 2017 Slides","tags":"pages","title":"Publications and Talks"},{"url":"pages/theteam.html.html","text":"The Team working on the CMS Big Data Project Fermi National Accelerator Laboratory Matteo Cremonesi Oliver Gutsche Bo Jayatilaka Jim Kowalkowski Saba Sehrish Princeton University Peter Elmer Jim Pivarski Alexey Svyatkovskiy CERN IT Department Maria Girone Luca Canali Kacper Surdy Vaggelis Motesnitsalis Simons Foundation Ian Fisk University of Iowa Viktor Khristenko","tags":"pages","title":"The Team"}]}