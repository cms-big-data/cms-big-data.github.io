{"pages":[{"url":"pages/contact.html.html","text":"Contact Oliver Gutsche Communication The project communicates through: Google Group: cms-big-data-project@googlegroups.com (link to subscribe) Slack: Ask for an invite to our Slack team cmsbigdataproject.slack.com or contact Oliver Gutsche Meetings The projects tries to meet bi-weekly. The meetings are announced on the Google group and in slack and Exchange invites are sent out. The meetings have an indico agenda in this indico category . Meetings notes are published after the meeting","tags":"pages","title":"Contact and Communication"},{"url":"pages/datareduction.html.html","text":"CERN openlab/Intel CMS Data Reduction Facility","tags":"pages","title":"CERN openlab/Intel CMS Data Reduction Facility"},{"url":"pages/fullanalysis.html.html","text":"Full HEP Analysis in Apache Spark","tags":"pages","title":"Full HEP Analysis in Apache Spark"},{"url":"pages/hpc.html.html","text":"Big Data Analysis at HPC centers","tags":"pages","title":"Big Data Analysis at HPC centers"},{"url":"pages/.html","text":"The CMS Big Data Project explores the applicability of open source data analytics toolkits to the HEP data analysis challenge Experimental Particle Physics has been at the forefront of analyzing the world's largest datasets for decades. The HEP community was amongst the first to develop suitable software and computing tools for this task. In recent times, new open source toolkits and systems collectively called \"Big Data\" technologies have emerged to support the analysis of Petabyte and Exabyte datasets. While the principles of data analysis in HEP have not changed (filtering and transforming experiment-specific data formats), these new technologies use different approaches and promise a fresh look at analysis of very large datasets and could potentially reduce the time-to-physics with increased interactivity. The CMS Big Data Project explores these new open source data analytics toolkits and has the following goals Reduce time-to-physics Educate our graduate students and post docs to use industry-based technologies Improves chances on the job market outside academia Increases the attractiveness of our field Use tools developed in larger communities reaching outside of our field The starting point is Apache Spark and we are working on the following thrusts Full Analysis in Apache Spark CERN openlab/Intel CMS Big Data Reduction Facility Big Data analytics at HPC centers All thrusts are based on reproducing a CMS physics analysis with open source data analytics frameworks in various settings, based on Apache Spark. We are planning to use the following list of metrics to characterize the performance of the solutions: Performance Metrics","tags":"pages","title":""},{"url":"pages/metrics.html.html","text":"Application metrics How quickly can I reduce how many events? Depends on reduction factor size per event how much of the event is accessed during reduction (to make decision (skimming) and also to pass on to output (slimming)) System metrics memory usage and caching strategy I/O metrics spark inbuilt metrics CPU time of all executors time spent on garbage in garbage collection, time in serialization from HDFS you get rows and data read from HDFS measure network traffic, important for reading from EOS","tags":"pages","title":"Performance Metrics"},{"url":"pages/pubsntalks.html.html","text":"Publications \"Big Data in HEP: A comprehensive use case study\" Proceedings for 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP 2016) accepted for publication arXiv:1703.04171 Talks \"Big Data Reduction - Introduction\" Presenter: Oliver Gutsche CMS Spring Offline and Computing Week 2016 April 04, 2016 Slides (password protected) \"Big Data\" in HEP: A comprehensive use case study\" Presenter: Oliver Gutsche 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP 2016) October 13, 2016 Slides \"Big Data Project : Status and Outlook\" Presenter: Oliver Gutsche CMS Fall Offline and Computing Week 2016 November 10, 2016 Slides (password protected) \"Intel Big Data Project: CMS Physics Data Reduction use case\" Presenter: Oliver Gutsche CERN openlab Technical Workshop December 09, 2016 Slides \"Status of CMS Big Data Project\" Presenter: Oliver Gutsche R&D meeting of CMS Spring Offline and Computing Week 2017 April 04, 2017 Slides (password protected) \"Data Analytics in Physics Data Reduction\" Presenter: Oliver Gutsche CERN openlab workshop on Machine Learning and Data Analytics April 27, 2017 Slides \"Infrastructure for Large Scale HEP data analysis\" Presenter: Matteo Cremonesi DS@HEP 2017 at Fermilab May 11, 2017 Slides \"A path toward HEP data analysis using high performance computing\" Presenter: Saba Sehrish DS@HEP 2017 at Fermilab May 11, 2017 Slides","tags":"pages","title":"Publications and Talks"},{"url":"pages/theteam.html.html","text":"The Team working on the CMS Big Data Project Fermi National Accelerator Laboratory Matteo Cremonesi Oliver Gutsche Bo Jayatilaka Jim Kowalkowski Saba Sehrish Princeton University Peter Elmer Jim Pivarski Alexey Svyatkovskiy CERN IT Department Maria Girone Luca Canali Kacper Surdy Vaggelis Motesnitsalis Simons Foundation Ian Fisk University of Iowa Viktor Khristenko","tags":"pages","title":"The Team"}]}